{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>![pune video](https://www.loksatta.com/wp-cont...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>![poverty alleviation in Maharashtra](https://...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>![Sanjay shirsat marathi news](https://www.lok...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>![डॉ. आंबेडकरांच्या मुद्द्यावरून काँग्रेसचा वा...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>![Horoscope Today Friday 03 January 2025](http...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>[Embedded Content](https://www.googletagmanage...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>![Ex PM Manmohan Singh Admitted To AIIMS In De...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>![Tejashri Pradhan](https://www.loksatta.com/w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>![water channel in street near Balaji Temple i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>![declining number of girls in secondary educa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>921 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  sentiment\n",
       "0    ![pune video](https://www.loksatta.com/wp-cont...          0\n",
       "1    ![poverty alleviation in Maharashtra](https://...          0\n",
       "2    ![Sanjay shirsat marathi news](https://www.lok...          0\n",
       "3    ![डॉ. आंबेडकरांच्या मुद्द्यावरून काँग्रेसचा वा...          0\n",
       "4    ![Horoscope Today Friday 03 January 2025](http...          0\n",
       "..                                                 ...        ...\n",
       "916  [Embedded Content](https://www.googletagmanage...          0\n",
       "917  ![Ex PM Manmohan Singh Admitted To AIIMS In De...          0\n",
       "918  ![Tejashri Pradhan](https://www.loksatta.com/w...          0\n",
       "919  ![water channel in street near Balaji Temple i...          0\n",
       "920  ![declining number of girls in secondary educa...          0\n",
       "\n",
       "[921 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"marathi_sentiment_dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"tweets-train (1).csv\")\n",
    "df1=pd.read_csv(\"tweets-test.csv\")\n",
    "df2=pd.read_csv(\"tweets-valid.csv\")\n",
    "df3=pd.read_csv(\"tweets-extra.csv\")\n",
    "\n",
    "df = pd.concat([df, df1, df2, df3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       " 1    7643\n",
       "-1    5447\n",
       " 0    5288\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.735038084874864\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.76      0.76      1129\n",
      "           0       0.67      0.66      0.66      1040\n",
      "           1       0.77      0.77      0.77      1507\n",
      "\n",
      "    accuracy                           0.74      3676\n",
      "   macro avg       0.73      0.73      0.73      3676\n",
      "weighted avg       0.73      0.74      0.73      3676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load your dataset\n",
    "\n",
    "tweets = df['tweet']\n",
    "labels = df['label']\n",
    "\n",
    "# Preprocess text (basic cleaning)\n",
    "import re\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|pic\\.twitter\\.com\\S*', '', text)  # Remove URLs\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Remove punctuation\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "tweets = tweets.apply(clean_text)\n",
    "\n",
    "# Vectorize text using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(tweets).toarray()\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Predict on new data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['काल महापूर आल्यामुळे लोकांचे खूप नुकसान झाले.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.53618768, 0.32771876, 0.13609356]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tweet = [\"काल महापूर आल्यामुळे लोकांचे खूप नुकसान झाले.\"]\n",
    "new_tweet_cleaned = [clean_text(tweet) for tweet in new_tweet]\n",
    "new_tweet_vectorized = tfidf.transform(new_tweet_cleaned).toarray()\n",
    "predicted_label = model.predict(new_tweet_vectorized)\n",
    "print(new_tweet_cleaned)\n",
    "model.predict_proba(new_tweet_vectorized)\n",
    "# print(\"Predicted Sentiment:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7848204570184983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.82      0.81      1129\n",
      "           0       0.72      0.69      0.70      1040\n",
      "           1       0.82      0.82      0.82      1507\n",
      "\n",
      "    accuracy                           0.78      3676\n",
      "   macro avg       0.78      0.78      0.78      3676\n",
      "weighted avg       0.78      0.78      0.78      3676\n",
      "\n",
      "Pipeline saved as 'tweet_sentiment_pipeline.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "\n",
    "# Load your dataset\n",
    "# Assuming your dataset is loaded in a DataFrame named `df`\n",
    "# Replace with your actual data loading code\n",
    "# Example: df = pd.read_csv(\"your_dataset.csv\")\n",
    "tweets = df['tweet']\n",
    "labels = df['label']\n",
    "\n",
    "# Preprocess text (basic cleaning)\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|pic\\.twitter\\.com\\S*', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Remove punctuation\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "tweets = tweets.apply(clean_text)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(tweets, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000)),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the pipeline\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Serialize the pipeline\n",
    "with open('tweet_sentiment_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline, f)\n",
    "\n",
    "print(\"Pipeline saved as 'tweet_sentiment_pipeline.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('tweets-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = test_data['tweet']  # Extract text\n",
    "true_labels = test_data['label']  # Extract true labels\n",
    "\n",
    "texts_cleaned = [clean_text(tweet) for tweet in test_data['tweet']]\n",
    "X_test = tfidf .transform(texts_cleaned).toarray()\n",
    "predicted_labels = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5235555555555556\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.67      0.43      0.52       750\n",
      "     Neutral       0.49      0.61      0.54       750\n",
      "    Positive       0.48      0.53      0.50       750\n",
      "\n",
      "    accuracy                           0.52      2250\n",
      "   macro avg       0.55      0.52      0.52      2250\n",
      "weighted avg       0.55      0.52      0.52      2250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=['Negative', 'Neutral', 'Positive']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
